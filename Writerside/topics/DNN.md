# DNN
**DNN(Deep Neural Network)**은 다층 퍼셉트론(Multilayer Perceptron, MLP)을 기반으로 한 신경망 구조로, 여러 개의 은닉층을 쌓은 인공신경망입니다. 일반적인 인공신경망(Artificial Neural Network, ANN)은 입력층, 은닉층, 출력층으로 구성되며, DNN은 특히 이 은닉층이 여러 개일 때를 지칭합니다.

## DNN 구성요소
1. 입력층 (Input Layer): 모델에 주어진 데이터가 처음 들어가는 층입니다. 입력층의 노드 수는 주어진 데이터의 차원에 따라 결정됩니다. 예를 들어, 이미지 데이터라면 각 픽셀 값이 입력값이 됩니다.
2. 은닉층 (Hidden Layer): 입력 데이터를 처리하고 학습하는 핵심 층입니다. DNN에서는 여러 개의 은닉층이 쌓여 더 깊은 구조를 이루며, 각 층에서는 가중치와 편향을 적용하여 데이터를 변환합니다. 은닉층이 많을수록 모델은 더 복잡한 패턴을 학습할 수 있지만, 학습 속도가 느려질 수 있고 과적합(overfitting)의 위험도 있습니다.
3. 활성화 함수 (Activation Function): 각 은닉층에서 출력된 값을 변환하는 함수입니다. DNN에서 자주 사용되는 활성화 함수로는 ReLU(Rectified Linear Unit), Sigmoid, Tanh 등이 있습니다. 활성화 함수는 모델에 비선형성을 도입하여 복잡한 패턴을 학습할 수 있게 만듭니다.
   * ReLU: 음수는 0으로 변환하고, 양수는 그대로 출력하는 함수.
   * Sigmoid: 출력값을 0과 1 사이로 제한하는 함수로, 주로 이진 분류에서 사용됨.
   * Tanh: 출력값을 -1과 1 사이로 제한하는 함수로, Sigmoid보다 넓은 범위의 값을 제공함.
4. 출력층 (Output Layer): DNN의 마지막 층으로, 예측값을 출력하는 층입니다. 분류 문제라면 Softmax와 같은 함수를 통해 각 클래스에 대한 확률을 출력하며, 회귀 문제에서는 선형 출력층을 사용합니다.

## DNN 특징
* 깊은 구조: DNN은 여러 층을 통해 입력 데이터를 점진적으로 추상화하여 복잡한 패턴을 학습할 수 있습니다. 처음에는 단순한 저수준 특징을 학습한 후, 점점 더 복잡한 고수준 특징을 학습하게 됩니다.
* 비선형성: 활성화 함수 덕분에 DNN은 비선형 데이터를 잘 처리할 수 있습니다. 여러 층을 쌓음으로써 다양한 비선형 패턴을 학습할 수 있습니다.
* 가중치와 편향: DNN은 각 층의 노드마다 가중치(weight)와 편향(bias)을 학습합니다. 이 값들이 데이터를 변환하는데 중요한 역할을 하며, 최종적으로 학습된 모델의 성능을 좌우합니다.
* 학습 과정: DNN은 역전파(backpropagation) 알고리즘을 통해 가중치와 편향을 업데이트하며 학습합니다. 역전파는 출력층에서 계산된 손실(loss)을 기반으로 각 층의 가중치를 조정하여 예측값을 더 정확하게 만듭니다.

## DNN vs CNN
* 구조적 차이: CNN은 주로 이미지나 시각적 데이터를 처리하기 위해 개발되었고, 합성곱(Convolution)을 통해 지역적 특성을 학습하는 반면, DNN은 모든 입력값을 완전 연결(Fully Connected) 방식으로 처리합니다.
* 용도: CNN은 이미지 데이터 처리에 특화된 반면, DNN은 더 일반적인 형태의 데이터에 적용할 수 있습니다. 예를 들어, 텍스트, 음성, 일반적인 수치 데이터를 처리하는 데도 사용됩니다.
