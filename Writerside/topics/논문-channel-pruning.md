# 논문_channel_pruning

1. 개요 (Abstract)
   * **채널 프루닝(Channel Pruning)** 은 CNN(Convolutional Neural Networks)을 가속화하기 위한 방법으로, 중요하지 않은 채널을 제거하여 모델을 간소화하고 연산 속도를 높이는 방법을 제안합니다.
   * LASSO 회귀를 기반으로 채널 선택을 수행하며, 네트워크에서 중복 채널을 제거해 성능을 최적화합니다.
   * VGG-16 모델에서 이 방법을 사용했을 때, 0.3%의 정확도 손실로 5배의 가속 성능을 달성했으며, ResNet과 Xception과 같은 최신 네트워크에서도 1.4%~1.0%의 성능 저하로 2배의 가속을 달성하였습니다.
2. 관련 연구 (Related Work)
   * 최적화 구현(Optimized Implementation), 양자화(Quantization), 구조적 단순화(Structured Simplification) 등의 방법들이 CNN 가속화에 기여하고 있으며, 이 논문에서는 채널 프루닝에 중점을 둡니다.
   * 기존 연구에서는 가중치 크기에 기반한 연결 가지치기 및 Truncated SVD와 같은 방법들이 사용되었으며, 이 연구에서는 채널 간 중복성을 제거하여 네트워크를 효율화합니다.
3. 프루닝 공식화 (Formulation)
   * 채널 프루닝은 입력 피처 맵에서 채널을 선택하고, 선택된 채널을 통해 출력 피처 맵을 재구성하는 두 단계로 이루어집니다.
   * LASSO 회귀를 사용하여 중요한 채널을 선택하고, 선형 최소 제곱(Least Square)을 통해 출력 재구성 오류를 최소화합니다.
4. 실험 (Experiments)
   * VGG-16, ResNet, Xception 네트워크에서 채널 프루닝을 적용한 실험을 수행했습니다.
   * VGG-16: 프루닝을 통해 2배 가속 시 정확도 손실 없이, 4배 가속 시에도 1%의 정확도 손실만으로 가속화에 성공했습니다.
   * ResNet 및 Xception: ResNet에서 1.4%, Xception에서 1%의 성능 저하로 2배 가속을 달성했습니다.
5. 결론 (Conclusion)
   * 본 논문은 채널 프루닝 기법을 통해 CNN에서 성능 저하를 최소화하면서도 추론 속도를 높이는 방법을 제안하였습니다.
   * 다양한 신경망 아키텍처에서 정확도를 유지하면서도 추론 속도를 가속화할 수 있음을 입증했습니다