# 하드웨어 가속 시스템(임베디드)

## Introduction
* **딥 신경망(DNN)** 은 많은 분야에서 중요한 응용 프로그램으로 자리 잡고 있으며, 특히 임베디드 시스템에서 보안, 개인정보 보호, 지연 시간, 에너지 절약 및 전력 관리와 관련된 많은 이점을 제공함.
* 그러나 임베디드 시스템에서 신경망을 배포하려면 제한된 자원을 가진 장치에서 많은 계산을 수행해야 하기 때문에 하드웨어적인 어려움이 존재함. 이를 해결하기 위해 하드웨어 가속이 필요함

## Neural Network Computing in Embedded Systems
* **신경망 계산** 은 계산량이 매우 많기 때문에, 기존에는 계산 집약적인 작업을 원격 고성능 컴퓨팅(HPC) 클러스터로 오프로드하는 방식이 사용됨. 이러한 방법은 임베디드 장치의 하드웨어 요구 사항을 줄여주지만, 네트워크 안정성, 지연 시간, 보안과 같은 문제들이 발생함.
* 하지만, 프로세서 기술의 발전과 동적 전력 관리(DPM) 같은 하드웨어 관리 기술의 혁신 덕분에 점점 더 많은 임베디드 장치들이 낮은 전력 소모로도 신경망 계산을 자체적으로 처리할 수 있게 됨.
* 예를 들어, 자율 시스템이나 실시간 제어 시스템에서는 지연 시간과 네트워크 안정성이 중요한 요소이기 때문에, 신경망 계산을 임베디드 장치 내에서 직접 처리하는 것이 더 나은 선택일 수 있음.

## Driving Neural Network Computing into Embedded Systems(신경망을 임베디드시스템에서 구동)
* 임베디드 시스템에서 신경망 계산을 실행하는 이유는 응용 프로그램, 시장(산업, 소비자 등) 등에 따라 다양하지만, 주로 다음과 같은 이유가 있음:
  1. 신뢰성: 네트워크 연결이 상실되면 원격 계산 클러스터를 사용하는 방식에서 서비스 중단이 발생할 수 있음. 이는 사용자의 불편을 초래하거나, 자율 주행차와 같은 시스템에서는 안전성 문제가 발생할 수 있음.
  2. 보안성: 원격 서버로 데이터를 전송하는 과정에서 보안 공격에 취약할 수 있으며, 이를 임베디드 시스템 내부에서 계산함으로써 데이터 유출 위험을 줄일 수 있음.
  3. 개인정보 보호: 원격 클러스터로 개인 정보를 전송하는 대신, 임베디드 장치 내부에서 데이터를 처리함으로써 개인정보 보호 문제를 해결할 수 있음.
  4. 지연 시간: 실시간으로 처리해야 하는 시스템에서는 지연 시간이 성능에 큰 영향을 미치며, 임베디드 시스템 내부에서 신경망을 처리하면 지연 시간을 최소화할 수 있음.
  5. 대역폭: 클라우드 기반의 신경망 처리 방식에서는 대량의 데이터를 전송해야 하므로 네트워크 대역폭이 요구되며, 임베디드 장치 내부에서 처리함으로써 이러한 문제를 해결할 수 있음.
  6. 에너지 및 전력: 원격 클러스터로 데이터를 전송하는 데 드는 에너지를 절약하고, 계산에 필요한 에너지를 임베디드 시스템 자체에서 사용하는 방식으로 전환할 수 있음

## Considerations for Choosing Embedded Processing Solutions
* 임베디드 처리 솔루션을 선택할 때 고려해야 할 다양한 요소가 존재하며, 이는 응용 프로그램의 요구 사항을 충족시키고 하드웨어 비용을 최소화하는 데 중요한 역할을 함.
  1. 애플리케이션 실행 이해: 가속기는 독립적인 처리 장치가 아니며, 임베디드 시스템의 일반적인 CPU와 협력하여 작업을 처리함. 가속기는 애플리케이션의 특정 부분을 처리하며, 각 부분의 병렬 처리 여부에 따라 적합한 가속기 선택이 필요함.
  2. 작업 부하와 성능 요구 사항 분석: 각 애플리케이션의 특성에 따라 필요한 성능을 분석하여 적합한 하드웨어를 선택함. 이를 통해 성능 최적화 방법을 결정할 수 있음. 예를 들어, 메모리 속도가 중요한 경우 대역폭을 높이는 것이 도움이 됨.
  3. 최적 운영 포인트 결정: 성능만 고려하는 것이 아니라, 전력, 에너지, 발열, 신뢰성 등을 고려하여 최적의 운영 포인트를 찾아야 함

## Hardware Acceleration Options
* 임베디드 시스템에서 신경망 계산을 가속화하는 데 사용할 수 있는 다양한 하드웨어 옵션이 존재함:
  1. CPU: 고성능 컴퓨팅에서 신경망 추론 작업을 빠르게 처리하지만, 전력 효율성 면에서는 다른 하드웨어 옵션보다 열세임.
  2. GPU: 대규모 병렬 처리를 통해 신경망 계산을 가속화하는 데 매우 적합하며, 주로 학습 과정에서 사용됨.
  3. FPGA: 특정 신경망 계산을 위한 맞춤형 데이터 경로를 설계하여 전력 효율성을 높일 수 있지만, 개발 시간이 더 오래 걸림.
  4. ASIC: 매우 높은 성능과 전력 효율성을 제공하지만, 개발 비용이 많이 들고, 업데이트가 어렵다는 단점이 있음

## Commercial Options for Neural Network Acceleration
* 상용화된 임베디드 하드웨어 가속 옵션:
1. Raspberry Pi 4:
   * 저전력, 저비용의 단일 보드 컴퓨터로, 주로 저사양 임베디드 시스템에서 사용됩니다.
   * GPGPU나 전용 신경망 가속기는 포함되지 않으며, ARM Cortex-A72 기반의 CPU와 Videocore VI GPU를 사용합니다.

2. Arduino Portenta H7:
   * ARM Cortex-M7 기반의 임베디드 보드로, GPGPU 지원이나 전용 신경망 가속기는 포함되지 않으며, 저전력 임베디드 프로세싱을 위한 옵션입니다.

3. NVIDIA Jetson TX2:
   * Pascal 아키텍처 기반의 GPU와 256 CUDA 코어를 갖춘 고성능 임베디드 플랫폼입니다.
   * ARM Cortex-A57 기반의 CPU와 8GB LPDDR4 메모리를 사용하여 고성능 신경망 계산을 지원합니다.

4. NVIDIA Jetson AGX Xavier:
   * Jetson TX2보다 고성능을 제공하며, 512 CUDA 코어와 64개의 Tensor 코어를 갖춘 Volta 아키텍처 기반의 GPU를 사용합니다.
   * 32GB LPDDR4 메모리와 8코어 ARM CPU로 높은 성능과 효율적인 신경망 계산을 지원합니다.

5. Edge TPU:
   * Google의 TPU를 경량화한 버전으로, 엣지 장치에서 신경망 가속화를 지원합니다.
   * ARM Cortex-A53 및 M4F CPU가 통합되어 있으며, GC7000 Lite Graphics를 통해 저전력 신경망 계산을 지원합니다.

6. Intel Neural Compute Stick 2:
   * Intel Movidius Myriad X VPU를 기반으로 하는 소형 컴퓨팅 장치로, USB 인터페이스를 통해 다른 시스템에 연결하여 신경망 계산을 가속화할 수 있습니다.
   * 16개의 스트리밍 하이브리드 코어가 통합된 VPU를 통해 저전력 신경망 처리 성능을 제공합니다.

7. Xilinx Zynq FPGA:
   * 프로그램 가능한 SoC로, 재구성 가능한 FPGA와 ARM Cortex-A9 또는 A53 CPU를 하나의 패키지로 통합한 시스템입니다.
   * Python 기반 PYNQ를 통해 FPGA를 프로그래밍할 수 있으며, 신경망 추론 가속을 위해 사용됩니다.

8. Tesla Full Self-Driving (FSD) Chip:
   * Tesla의 자율 주행 시스템에 사용되는 전용 임베디드 프로세싱 솔루션으로, 상업용으로 제공되지는 않지만 임베디드 신경망 처리의 좋은 예시입니다.
   * FSD 칩에는 12개의 Cortex-A72 CPU 코어와 96×96 MAC(multiply-and-accumulate) 유닛이 통합되어 있어 신경망 추론을 빠르게 처리합니다​(2_HWAccel_CH2).
   
9. HPC Processor (예: AMD EPYC 7742, NVIDIA A100):
   * HPC 프로세서는 일반적으로 고성능 컴퓨팅을 위한 CPU와 GPU를 포함합니다.
   * AMD EPYC 7742는 64개 코어와 128개의 하드웨어 스레드를 지원하는 CPU로, 높은 클럭 속도와 강력한 병렬 처리 성능을 제공합니다.
   * NVIDIA A100은 6,912 CUDA 코어와 432 Tensor 코어를 갖춘 GPU로, 대규모 신경망 학습과 추론 작업에 적합합니다

## Software Frameworks for Neural Networks
* 임베디드 하드웨어에서 신경망을 실행하기 위해 다양한 소프트웨어 프레임워크가 사용됨:
  * TensorFlow: Google에서 개발된 딥러닝 프레임워크로, 다양한 하드웨어 플랫폼에서 신경망을 실행할 수 있음.
  * TensorFlow Lite: 모바일 및 IoT 장치에서 신경망을 실행하도록 최적화된 버전으로, 그래프 최적화 및 모델 경량화를 지원함.
  * TensorRT: NVIDIA에서 제공하는 고성능 추론 프레임워크로, NVIDIA GPU에서 최적화된 추론을 실행함. 혼합 정밀도 계산(INT8, FP16 등)을 지원하여 성능을 최적화함.
  * Caffe 및 Caffe2: 주로 CNN 기반 모델을 실행하는 데 사용되며, 대규모 학습 및 모바일 배포를 지원함.
  * PyTorch: 동적 그래프 생성을 지원하여 유연한 개발 환경을 제공하며, GPU 가속을 지원함.
  * Intel Movidius Neural Compute SDK: Intel Movidius VPU 기반 장치에서 신경망을 실행하기 위한 SDK로, C/C++ 및 Python 지원 도구를 포함함.
  * FPGA 프레임워크: Xilinx PYNQ FPGA와 같은 플랫폼에서 딥러닝을 실행하기 위한 소프트웨어 프레임워크로, FINN과 같은 도구가 FPGA에서 신경망을 최적화할 수 있도록 지원함​